other_configs_path:   # 靠后的配置文件会覆盖前面的配置，当前文件会覆盖这个列表里的
- examples/pgm_config.example.yaml

# 启用抓取器，这里启用了所有可用的，可以删除不需要的 TODO 默认应该少开一点
enabled_web_scraper:
  src.scraper.examples:
  - bentoml
  - cslrxyz
  - cnu_daily
  - gatesnotes
  - career_tsinghua
  - old_stone
  - hot_juejin
  - hot_bilibili
  - mangacopy
  - chiphell
  - youtube_channel
  - bilibili_up
# 暂时没有维护无法正常运行的抓取器
# - newsletter

scraper_profile:
- examples/scraper_profile.example.yaml

# 不了解的话建议删除
enable_agent_server: true
known_agents:
- name: vfly2_direct_agent
  connect_method: direct_websocket
  agent_uri: ws://127.0.0.1:8537/ws_connect
  enabled_scrapers:
  - BentoMLBlog
  - YoutubeChannel
- name: vfly2_agent
  connect_method: reverse_websocket

# *****下面的配置都有默认值，删除也不影响运行，如果有需要可以自定义*****

# 请求时的相关配置
query_cache_maxsize: 100
query_cache_ttl_s: 3600
query_username: vfly2
query_password: "123456"
query_bedtime:   # 睡眠时间里，管理员的请求走缓存路径，减少资源消耗
- ["01:30", "06:30"]


# 抓取器的默认配置，如果没有在 scraper_profile 文件里定义相关量，就会使用这里的
crawler_default_cfg:
  timezone: Asia/Shanghai
  run_everyday_at: ["05:00", "11:00", "17:00", "23:00"]
  WAIT: 5
  amount_when_firstly_add: 10
  max_of_rss_items: 50
  prefer_agent: self
  # 为了节省内存，限制只能打开一个浏览器，一个浏览器可以开多个 context
  # 每个抓取器实例需要一个 context 进而打开 page 访问网页，这里限制同时打开的 context 的个数，如果内存不够可以调小
  max_opening_context: 2

enable_s2r_c: false # 如果运行，程序中的一些错误会以文章的形式发表到 source2RSS 上，方便查看
port: 8536 # 如果 enable_s2r_c 为真，这个必须填写为程序监听的端口号
