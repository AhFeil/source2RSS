other_configs_path:   # 靠后的配置文件会覆盖前面的配置，当前文件会覆盖这个列表里的
- examples/pgm_config.example.yaml

# 启用抓取器，这里启用了所有可用的，可以删除不需要的 TODO 默认应该少开一点
enabled_web_scraper:
  src.scraper.examples:
  - bentoml
  - dotcompress
  - cslrxyz
  - cnu_daily
  - gatesnotes
  - career_tsinghua
  - old_stone
  - hot_juejin
  - hot_bilibili
  - mangacopy
  - chiphell
  - youtube_channel
  - telegram_channel
  - bilibili_up
  - juejin_user

# 管理员名称和密码
query_username: vfly2
query_password: "123456"


# *****下面的配置都有默认值，删除也不影响运行，如果有需要可以自定义*****

# 对抓取器进行定制，可参考示例文件进行
# scraper_profile:
# - examples/scraper_profile.example.yaml

# 时区，影响处有两个：定期运行时，设置为不同时区的话，实际运行的时间不同；生成 RSS 中，时间相关的量
timezone: Asia/Shanghai

# 抓取器的默认配置，如果没有在 scraper_profile 文件里设置相应的值，就会使用这里的
crawler_default_cfg:
  run_everyday_at: ["05:00", "11:00", "17:00", "23:00"]
  WAIT: 5
  amount_when_firstly_add: 10
  interval_between_each_instance: 1 # seconds
  max_of_rss_items: 50
  prefer_agent: self
  # 为了节省内存，限制只能打开一个浏览器，而一个浏览器可以开多个 context，每个抓取器实例需要一个 context 访问网页
  # 这里限制同时打开的 context 的个数，如果内存足够可以调大
  max_opening_context: 1


# *****下面的配置对应的功能尚不成熟，不建议使用*****

enable_agent_server: true  # 设置为 True 代表此实例可以调度其他 agent
known_agents:
- name: vfly2_direct_agent
  connect_method: direct_websocket
  agent_uri: ws://127.0.0.1:8537/ws_connect
  enabled_scrapers:
  - BentoMLBlog
  - BilibiliUp
  - YoutubeChannel
- name: vfly2_agent
  connect_method: reverse_websocket
